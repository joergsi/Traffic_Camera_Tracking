{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a4PF3JBkGlNY"
   },
   "source": [
    "# Basic Setup\n",
    "\n",
    "Installing Pytorch and Detectron2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OmP1ykzXGZCU",
    "outputId": "df559e97-4114-40d6-a250-5cfbeac3cfa3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyyaml==5.1 in c:\\users\\balaji\\desktop\\traffic_camera_tracking\\lib\\site-packages (5.1)\n",
      "1.8.0 True\n"
     ]
    }
   ],
   "source": [
    "# install dependencies: \n",
    "!pip install pyyaml==5.1\n",
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "USnAkQi2GyPU"
   },
   "source": [
    "# Importing the required packages and dependencies\n",
    "\n",
    "Some packages like the google.colab packages must be prevented from getting imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "pW5CUJtOGug1"
   },
   "outputs": [],
   "source": [
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "from os import path\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.data.datasets import register_coco_instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "69kSEow7LjQM"
   },
   "source": [
    "## FFMPEG Installation\n",
    "\n",
    "If the code is being executed on a local linux machine, then this step can be skipped if you already have FFMPEG.\n",
    "Also, this completely doesnot work for Windows PC !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "jJE60UotLgDg",
    "outputId": "d7051d02-cf99-41f4-8353-4dc1f47798d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FFMPEG Installation finished.\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import os, urllib.request\n",
    "HOME = os.path.expanduser(\"~\")\n",
    "pathDoneCMD = f'{HOME}/doneCMD.sh'\n",
    "if not os.path.exists(f\"{HOME}/.ipython/ttmg.py\"):\n",
    "    hCode = \"https://raw.githubusercontent.com/yunooooo/gcct/master/res/ttmg.py\"\n",
    "    urllib.request.urlretrieve(hCode, f\"{HOME}/.ipython/ttmg.py\")\n",
    "\n",
    "from ttmg import (\n",
    "    loadingAn,\n",
    "    textAn,\n",
    ")\n",
    "\n",
    "loadingAn(name=\"lds\")\n",
    "textAn(\"Installing Dependencies...\", ty='twg')\n",
    "os.system('pip install git+git://github.com/AWConant/jikanpy.git')\n",
    "os.system('add-apt-repository -y ppa:jonathonf/ffmpeg-4')\n",
    "os.system('apt-get update')\n",
    "os.system('apt install mediainfo')\n",
    "os.system('apt-get install ffmpeg')\n",
    "clear_output()\n",
    "print('FFMPEG Installation finished.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n7TI8Lj96sgf"
   },
   "source": [
    "# Input Data\n",
    "\n",
    "The folder structure, in which all the clips and the associated annotations must be placed\n",
    "\n",
    "**!! Images directory is not required. It is created in the next code cell**\n",
    "\n",
    "```\n",
    "input/\n",
    "│\n",
    "└─── 1/\n",
    "│       1.mp4\n",
    "│       1_Annotations.json\n",
    "|       images/\n",
    "|            labels/\n",
    "|            frame_000001.jpg\n",
    "|            frame_000002.jpg and so on\n",
    "|\n",
    "└─── 2/\n",
    "│       2.mp4\n",
    "│       2_Annotations.json\n",
    "|       images/\n",
    "|            labels/\n",
    "|            frame_000001.jpg\n",
    "|            frame_000002.jpg and so on\n",
    "|\n",
    ".\n",
    ".\n",
    ".\n",
    "│   \n",
    "└─── {Clip_Number}/\n",
    "        {Clip_Number}.mp4\n",
    "        {Clip_Number}_Annotations.json\n",
    "        images/\n",
    "             labels/\n",
    "             frame_000001.jpg\n",
    "             frame_000002.jpg and so on\n",
    "```\n",
    "\n",
    "## Splitting the clips into frames\n",
    "In the below code cell, we are using FFMPEG Commands to split the clip into images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rJztU9NdLZOh",
    "outputId": "9206108b-eebe-434b-ca4a-228ef2908536"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\balaji\\Desktop\\Traffic_Camera_Tracking\\Main_Code\n",
      "D:\\Project_Escooter_Tracking\\input\n",
      "D:\\Project_Escooter_Tracking\\input\\16\n",
      "ffmpeg -i D:\\Project_Escooter_Tracking\\input\\16\\16.mp4 D:\\Project_Escooter_Tracking\\input\\16\\images\\frame_%06d.png\n",
      "D:\\Project_Escooter_Tracking\\input\\18\n",
      "ffmpeg -i D:\\Project_Escooter_Tracking\\input\\18\\18.mp4 D:\\Project_Escooter_Tracking\\input\\18\\images\\frame_%06d.png\n",
      "D:\\Project_Escooter_Tracking\\input\\2\n",
      "ffmpeg -i D:\\Project_Escooter_Tracking\\input\\2\\2.mp4 D:\\Project_Escooter_Tracking\\input\\2\\images\\frame_%06d.png\n",
      "D:\\Project_Escooter_Tracking\\input\\20\n",
      "ffmpeg -i D:\\Project_Escooter_Tracking\\input\\20\\20.mp4 D:\\Project_Escooter_Tracking\\input\\20\\images\\frame_%06d.png\n",
      "D:\\Project_Escooter_Tracking\\input\\21\n",
      "ffmpeg -i D:\\Project_Escooter_Tracking\\input\\21\\21.mp4 D:\\Project_Escooter_Tracking\\input\\21\\images\\frame_%06d.png\n",
      "D:\\Project_Escooter_Tracking\\input\\22\n",
      "ffmpeg -i D:\\Project_Escooter_Tracking\\input\\22\\22.mp4 D:\\Project_Escooter_Tracking\\input\\22\\images\\frame_%06d.png\n",
      "D:\\Project_Escooter_Tracking\\input\\23\n",
      "ffmpeg -i D:\\Project_Escooter_Tracking\\input\\23\\23.mp4 D:\\Project_Escooter_Tracking\\input\\23\\images\\frame_%06d.png\n",
      "D:\\Project_Escooter_Tracking\\input\\24\n",
      "ffmpeg -i D:\\Project_Escooter_Tracking\\input\\24\\24.mp4 D:\\Project_Escooter_Tracking\\input\\24\\images\\frame_%06d.png\n",
      "D:\\Project_Escooter_Tracking\\input\\25\n",
      "ffmpeg -i D:\\Project_Escooter_Tracking\\input\\25\\25.mp4 D:\\Project_Escooter_Tracking\\input\\25\\images\\frame_%06d.png\n",
      "D:\\Project_Escooter_Tracking\\input\\26\n",
      "ffmpeg -i D:\\Project_Escooter_Tracking\\input\\26\\26.mp4 D:\\Project_Escooter_Tracking\\input\\26\\images\\frame_%06d.png\n",
      "D:\\Project_Escooter_Tracking\\input\\27\n",
      "ffmpeg -i D:\\Project_Escooter_Tracking\\input\\27\\27.mp4 D:\\Project_Escooter_Tracking\\input\\27\\images\\frame_%06d.png\n",
      "D:\\Project_Escooter_Tracking\\input\\28\n",
      "ffmpeg -i D:\\Project_Escooter_Tracking\\input\\28\\28.mp4 D:\\Project_Escooter_Tracking\\input\\28\\images\\frame_%06d.png\n",
      "D:\\Project_Escooter_Tracking\\input\\29\n",
      "ffmpeg -i D:\\Project_Escooter_Tracking\\input\\29\\29.mp4 D:\\Project_Escooter_Tracking\\input\\29\\images\\frame_%06d.png\n",
      "D:\\Project_Escooter_Tracking\\input\\3\n",
      "ffmpeg -i D:\\Project_Escooter_Tracking\\input\\3\\3.mp4 D:\\Project_Escooter_Tracking\\input\\3\\images\\frame_%06d.png\n",
      "D:\\Project_Escooter_Tracking\\input\\30\n",
      "ffmpeg -i D:\\Project_Escooter_Tracking\\input\\30\\30.mp4 D:\\Project_Escooter_Tracking\\input\\30\\images\\frame_%06d.png\n",
      "D:\\Project_Escooter_Tracking\\input\\31\n",
      "ffmpeg -i D:\\Project_Escooter_Tracking\\input\\31\\31.mp4 D:\\Project_Escooter_Tracking\\input\\31\\images\\frame_%06d.png\n",
      "D:\\Project_Escooter_Tracking\\input\\32\n",
      "ffmpeg -i D:\\Project_Escooter_Tracking\\input\\32\\32.mp4 D:\\Project_Escooter_Tracking\\input\\32\\images\\frame_%06d.png\n",
      "D:\\Project_Escooter_Tracking\\input\\33\n",
      "ffmpeg -i D:\\Project_Escooter_Tracking\\input\\33\\33.mp4 D:\\Project_Escooter_Tracking\\input\\33\\images\\frame_%06d.png\n",
      "D:\\Project_Escooter_Tracking\\input\\34\n",
      "ffmpeg -i D:\\Project_Escooter_Tracking\\input\\34\\34.mp4 D:\\Project_Escooter_Tracking\\input\\34\\images\\frame_%06d.png\n",
      "D:\\Project_Escooter_Tracking\\input\\35\n",
      "ffmpeg -i D:\\Project_Escooter_Tracking\\input\\35\\35.mp4 D:\\Project_Escooter_Tracking\\input\\35\\images\\frame_%06d.png\n",
      "D:\\Project_Escooter_Tracking\\input\\36\n",
      "ffmpeg -i D:\\Project_Escooter_Tracking\\input\\36\\36.mp4 D:\\Project_Escooter_Tracking\\input\\36\\images\\frame_%06d.png\n",
      "D:\\Project_Escooter_Tracking\\input\\37\n",
      "ffmpeg -i D:\\Project_Escooter_Tracking\\input\\37\\37.mp4 D:\\Project_Escooter_Tracking\\input\\37\\images\\frame_%06d.png\n",
      "D:\\Project_Escooter_Tracking\\input\\38\n",
      "ffmpeg -i D:\\Project_Escooter_Tracking\\input\\38\\38.mp4 D:\\Project_Escooter_Tracking\\input\\38\\images\\frame_%06d.png\n",
      "D:\\Project_Escooter_Tracking\\input\\39\n",
      "ffmpeg -i D:\\Project_Escooter_Tracking\\input\\39\\39.mp4 D:\\Project_Escooter_Tracking\\input\\39\\images\\frame_%06d.png\n",
      "D:\\Project_Escooter_Tracking\\input\\4\n",
      "ffmpeg -i D:\\Project_Escooter_Tracking\\input\\4\\4.mp4 D:\\Project_Escooter_Tracking\\input\\4\\images\\frame_%06d.png\n",
      "D:\\Project_Escooter_Tracking\\input\\40\n",
      "ffmpeg -i D:\\Project_Escooter_Tracking\\input\\40\\40.mp4 D:\\Project_Escooter_Tracking\\input\\40\\images\\frame_%06d.png\n",
      "D:\\Project_Escooter_Tracking\\input\\41\n",
      "ffmpeg -i D:\\Project_Escooter_Tracking\\input\\41\\41.mp4 D:\\Project_Escooter_Tracking\\input\\41\\images\\frame_%06d.png\n",
      "D:\\Project_Escooter_Tracking\\input\\42\n",
      "ffmpeg -i D:\\Project_Escooter_Tracking\\input\\42\\42.mp4 D:\\Project_Escooter_Tracking\\input\\42\\images\\frame_%06d.png\n",
      "D:\\Project_Escooter_Tracking\\input\\43\n",
      "ffmpeg -i D:\\Project_Escooter_Tracking\\input\\43\\43.mp4 D:\\Project_Escooter_Tracking\\input\\43\\images\\frame_%06d.png\n",
      "D:\\Project_Escooter_Tracking\\input\\44\n",
      "ffmpeg -i D:\\Project_Escooter_Tracking\\input\\44\\44.mp4 D:\\Project_Escooter_Tracking\\input\\44\\images\\frame_%06d.png\n"
     ]
    }
   ],
   "source": [
    "# main_path refers to current working directory\n",
    "main_path = os.getcwd()\n",
    "print(main_path)\n",
    "# input_path refers to the folder containing the clips folders (as mentioned above in the diagram)\n",
    "#input_path = main_path + '/input'\n",
    "input_path = os.path.abspath(r'D:\\Project_Escooter_Tracking\\input')\n",
    "print(input_path)\n",
    "\n",
    "for dir in os.listdir(input_path):\n",
    "  clip_path = input_path + f'\\\\{dir}'\n",
    "  print(clip_path)\n",
    "  \n",
    "  image_path = clip_path + '\\\\images'\n",
    "  os.system(f'mkdir {image_path}')\n",
    "\n",
    "  labels_path = image_path + '\\\\labels'\n",
    "  os.system(f'mkdir {labels_path}')\n",
    "\n",
    "  clip_path += f'\\\\{dir}.mp4'\n",
    "\n",
    "  ffmpeg_command = 'ffmpeg -i ' + clip_path + \" \" + image_path + '\\\\frame_%06d.png'\n",
    "  print(ffmpeg_command)\n",
    "  os.system(ffmpeg_command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RGUbSvjLHOan"
   },
   "source": [
    "# Reading, manipulating and checking the annotations on the images\n",
    "\n",
    "### This code section is partly derived from Check_Dataset.ipynb and ReadJSON.py. \n",
    "---------------------------------------------------------------------\n",
    "\n",
    "This is my Custom Code for checking the dataset 😎. \n",
    "\n",
    "When we annotate in CVAT, for each clip we receive one annotation file. Unfortunately, these annotation files have _'frame numbers'_ that start only from 0 but Detectron 2 needs it to start from **1**.\n",
    "\n",
    "From a separate file in the repo called **ReadJSON.py**, I have written a script to combin all these annotation files into 3 files **Final_Annnotation_Train.json**, **Final_Annnotation_Valid.json** and **Final_Annnotation_Test.json** . The below given code cell replicates that.\n",
    "\n",
    "In the 2nd code cell, we are incrementing all the frame numbers by 1 and showing the images along with their labels for verfication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BsrvMpH46V0_",
    "outputId": "31f43860-d23b-4112-9583-0f3c1a7a7eba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed the following annotation files: \n",
      "  - D:\\Project_Escooter_Tracking\\input/16/16_Annotations.json\n",
      "  - D:\\Project_Escooter_Tracking\\input/18/18_Annotations.json\n",
      "  - D:\\Project_Escooter_Tracking\\input/2/2_Annotations.json\n",
      "  - D:\\Project_Escooter_Tracking\\input/20/20_Annotations.json\n",
      "  - D:\\Project_Escooter_Tracking\\input/21/21_Annotations.json\n",
      "  - D:\\Project_Escooter_Tracking\\input/22/22_Annotations.json\n",
      "  - D:\\Project_Escooter_Tracking\\input/23/23_Annotations.json\n",
      "  - D:\\Project_Escooter_Tracking\\input/24/24_Annotations.json\n",
      "  - D:\\Project_Escooter_Tracking\\input/25/25_Annotations.json\n",
      "  - D:\\Project_Escooter_Tracking\\input/26/26_Annotations.json\n",
      "  - D:\\Project_Escooter_Tracking\\input/27/27_Annotations.json\n",
      "  - D:\\Project_Escooter_Tracking\\input/28/28_Annotations.json\n",
      "  - D:\\Project_Escooter_Tracking\\input/29/29_Annotations.json\n",
      "  - D:\\Project_Escooter_Tracking\\input/3/3_Annotations.json\n",
      "  - D:\\Project_Escooter_Tracking\\input/30/30_Annotations.json\n",
      "  - D:\\Project_Escooter_Tracking\\input/31/31_Annotations.json\n",
      "  - D:\\Project_Escooter_Tracking\\input/32/32_Annotations.json\n",
      "  - D:\\Project_Escooter_Tracking\\input/33/33_Annotations.json\n",
      "  - D:\\Project_Escooter_Tracking\\input/34/34_Annotations.json\n",
      "  - D:\\Project_Escooter_Tracking\\input/35/35_Annotations.json\n",
      "  - D:\\Project_Escooter_Tracking\\input/36/36_Annotations.json\n",
      "  - D:\\Project_Escooter_Tracking\\input/37/37_Annotations.json\n",
      "  - D:\\Project_Escooter_Tracking\\input/38/38_Annotations.json\n",
      "  - D:\\Project_Escooter_Tracking\\input/39/39_Annotations.json\n",
      "  - D:\\Project_Escooter_Tracking\\input/4/4_Annotations.json\n",
      "  - D:\\Project_Escooter_Tracking\\input/40/40_Annotations.json\n",
      "  - D:\\Project_Escooter_Tracking\\input/41/41_Annotations.json\n",
      "  - D:\\Project_Escooter_Tracking\\input/42/42_Annotations.json\n",
      "  - D:\\Project_Escooter_Tracking\\input/43/43_Annotations.json\n",
      "  - D:\\Project_Escooter_Tracking\\input/44/44_Annotations.json\n",
      "\n",
      "Splitting the dataset into Train, Valid and Test is successfull\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\balaji\\\\Desktop\\\\Traffic_Camera_Tracking\\\\Main_Code/input/Test_1_Train.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-c71cadaeaf18>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[0mtest_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"{os.getcwd()}/input/{base_filename[:-5]}_Test.json\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"w\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    236\u001b[0m     \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_json\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Final training set file saved as: {train_file}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\balaji\\\\Desktop\\\\Traffic_Camera_Tracking\\\\Main_Code/input/Test_1_Train.json'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from copy import deepcopy\n",
    "import random\n",
    "\n",
    "# coco_format is the dict file which includes all the values that needs to be output in the final annotations json file\n",
    "# Some of the key values like 'licenses', 'info' and 'categories' are constant and declared at first here\n",
    "\n",
    "coco_format = {\n",
    "    \"licenses\": [{\n",
    "        \"name\": \"\",\n",
    "        \"id\": 0,\n",
    "        \"url\": \"\"\n",
    "    }],\n",
    "    \"info\": {\n",
    "        \"contributor\": \"Vishal Balaji\",\n",
    "        \"date_created\": \"\",\n",
    "        \"description\": \"Escooter Dataset\",\n",
    "        \"url\": \"\",\n",
    "        \"version\": \"\",\n",
    "        \"year\": \"\"\n",
    "    },\n",
    "    \"categories\": [{\n",
    "        \"id\": 1,\n",
    "        \"name\": \"Escooter\",\n",
    "        \"supercategory\": \"\"\n",
    "    }]\n",
    "}\n",
    "\n",
    "# The key values 'images' and 'annotations' needs to be processed and appended. The below given lines is the format for\n",
    "# those dicts.\n",
    "\"\"\"\n",
    "\"images\":[\n",
    "    {\n",
    "        \"id\":1,\n",
    "        \"width\": 1920,\n",
    "        \"height\": 1080,\n",
    "        \"file_name\":\"sdfa.PNG\",\n",
    "        \"license\":0,\n",
    "        \"flickr_url\": \"\",\n",
    "        \"coco_url\": \"\",\n",
    "        \"date_captured\": 0\n",
    "    }\n",
    "]\n",
    "\n",
    "\"annotations\":[\n",
    "    {\n",
    "        \"id\": 1,\n",
    "        \"image_id\": 55,\n",
    "        \"category_id\": 1,\n",
    "        \"segmentation\": [[]],\n",
    "        \"area\": {some area number in float},\n",
    "        \"bbox\": [].\n",
    "        \"iscrowd\": 0\n",
    "    }\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "# Path where the annotations are stored, when the repo is the path of current working directory\n",
    "#main_file_path = os.path.abspath(r'D:\\Carissma Video Copy\\Traffic Camera Tracking\\Finished')\n",
    "input_path = r'D:\\Project_Escooter_Tracking\\input'\n",
    "main_file_path = input_path\n",
    "\n",
    "# Declaration of empty lists that is later appended it with images and annotations.\n",
    "images_list = []\n",
    "annotations_list = []\n",
    "\n",
    "# Each image and annotations has an ID associated with it and it starts with 1.\n",
    "# These values are incremented as the images and annotations are being added.\n",
    "img_num = 1\n",
    "anno_num = 1\n",
    "\n",
    "\"\"\"\n",
    "Folder Structure\n",
    "\n",
    "This folder structure must be maintained as the code with Google Colab also works with the same structure.\n",
    "- Finished\n",
    "    - 2\n",
    "        - images\n",
    "        - annotations\n",
    "            - 2_Annotations.json\n",
    "        - 2.mp4\n",
    "    - 3\n",
    "        - images\n",
    "        - annotations\n",
    "            - 3_Annotations.json\n",
    "        - 3.mp4\n",
    "    - 4\n",
    "    .\n",
    "    .\n",
    "    .\n",
    "    .\n",
    "    - {Clip_Number}\n",
    "        - images (contains all images starting with 'frame_000001.jpg')\n",
    "        - annotations\n",
    "            - {Clip_Number}_Annotations.json\n",
    "        - {Clip_Number}.mp4\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "print(\"Processed the following annotation files: \")\n",
    "for clip_number, clips in enumerate(os.listdir(main_file_path)):\n",
    "    # Checking that only numbers are given as folder names for the clips\n",
    "    if all(char.isdigit() for char in clips):\n",
    "      # Path of the clips folder\n",
    "      clips_path = main_file_path + '/' + clips\n",
    "      # Path of the annotation of the clips\n",
    "      annotation_file = clips_path + f'/{str(clips)}_Annotations.json'\n",
    "\n",
    "      file = open(annotation_file)\n",
    "      json_file = json.load(file)\n",
    "      print(f'  - {annotation_file}')\n",
    "\n",
    "      # !! Testing purpose only for restricting number of annotations\n",
    "      # flag = 1\n",
    "      for annotations in json_file['annotations']:\n",
    "\n",
    "          anno_image_ID = annotations['image_id']\n",
    "          anno_ID = annotations['id']\n",
    "\n",
    "          image_filename = ''\n",
    "          for images in json_file['images']:\n",
    "              if images['id'] == anno_image_ID:\n",
    "                  image_filename = images['file_name']\n",
    "\n",
    "          filename = input_path + '/' + clips + '/images/' + image_filename\n",
    "          # The formats for 'images' dictionary and 'annotations' dictionary in COCO\n",
    "          image_dict = {\n",
    "              'id': img_num,\n",
    "              \"width\": 1920,\n",
    "              \"height\": 1080,\n",
    "              \"file_name\": filename,\n",
    "              \"license\": 0,\n",
    "              \"flickr_url\": \"\",\n",
    "              \"coco_url\": \"\",\n",
    "              \"date_captured\": 0\n",
    "          }\n",
    "          anno_dict = {\n",
    "              \"id\": anno_num,\n",
    "              'image_id': img_num,\n",
    "              \"category_id\": 1,\n",
    "              'segmentation': annotations['segmentation'],\n",
    "              'area': annotations['area'],\n",
    "              'bbox': annotations['bbox'],\n",
    "              'iscrowd': annotations['iscrowd']\n",
    "          }\n",
    "\n",
    "          # In the COCO-Format, every images and associated annotations are passed as array of dicts.\n",
    "          images_list.append(image_dict)\n",
    "          annotations_list.append(anno_dict)\n",
    "\n",
    "          # Incrementing the Image ID and Annotation ID for each loop\n",
    "          img_num += 1\n",
    "          anno_num += 1\n",
    "\n",
    "          # !! Meant only for testing purpose. To check with just 2 annotations per file\n",
    "          # if flag == 2:\n",
    "          #     break\n",
    "          # flag += 1\n",
    "\n",
    "      # Storing the processed arrays of images and annotations with their\n",
    "      # respective keys in the final dataset\n",
    "      # coco_format[\"images\"] = images_list\n",
    "      # coco_format[\"annotations\"] = annotations_list\n",
    "\n",
    "      file.close()\n",
    "\n",
    "      # !! Meant for testing purpose.\n",
    "      # if clip_number == 1:\n",
    "      #     break\n",
    "\n",
    "train_json = deepcopy(coco_format)\n",
    "valid_json = deepcopy(coco_format)\n",
    "test_json = deepcopy(coco_format)\n",
    "\n",
    "train_split = 0.8\n",
    "valid_split = 0.1\n",
    "test_split = 0.1\n",
    "\n",
    "# Function to split the whole dataset of images and annotations into train,\n",
    "# valid and test sets\n",
    "def splitDataset(images, annotations, trainSplit, validSplit):\n",
    "  trainSize = int(len(images) * trainSplit)\n",
    "  train_images = []\n",
    "  train_annotations = []\n",
    "  \n",
    "  copy_images = list(images)\n",
    "  copy_annotations = list(annotations)\n",
    "  while len(train_images) < trainSize:\n",
    "    index = random.randrange(len(copy_images))\n",
    "    train_images.append(copy_images.pop(index))\n",
    "    train_annotations.append(copy_annotations.pop(index))\n",
    "  \n",
    "\n",
    "  copySize = int(len(copy_images) * (validSplit/(1 - trainSplit)))\n",
    "  valid_images = []\n",
    "  valid_annotations = []\n",
    "\n",
    "  test_images = copy_images\n",
    "  test_annotations = copy_annotations\n",
    "  while len(valid_images) < copySize:\n",
    "    index = random.randrange(len(test_images))\n",
    "    valid_images.append(test_images.pop(index))\n",
    "    valid_annotations.append(test_annotations.pop(index))\n",
    "  \n",
    "  return [(train_images, train_annotations), (valid_images, valid_annotations), (test_images, test_annotations)]\n",
    "\n",
    "train_set, valid_set, test_set = splitDataset(images_list, annotations_list, 0.8, 0.1)\n",
    "print(\"\\nSplitting the dataset into Train, Valid and Test is successfull\\n\")\n",
    "\n",
    "train_json['images'] = train_set[0]\n",
    "train_json['annotations'] = train_set[1]\n",
    "\n",
    "valid_json['images'] = valid_set[0]\n",
    "valid_json['annotations'] = valid_set[1]\n",
    "\n",
    "test_json['images'] = test_set[0]\n",
    "test_json['annotations'] = test_set[1]\n",
    "\n",
    "# Code Snippet to automatically create new names for the many\n",
    "# .json files created during the testing\n",
    "base_filename = 'Test_'\n",
    "for numbers in range(20):\n",
    "    check_filename = base_filename + str(numbers+1) + '.json'\n",
    "    if check_filename not in os.listdir(os.getcwd()):\n",
    "        base_filename = check_filename\n",
    "        break\n",
    "\n",
    "\n",
    "# These lines writes all the dictionaries into the final required .json file\n",
    "# For train, valid and test individually\n",
    "train_file = f\"{os.getcwd()}/input/{base_filename[:-5]}_Train.json\"\n",
    "valid_file = f\"{os.getcwd()}/input/{base_filename[:-5]}_Valid.json\"\n",
    "test_file = f\"{os.getcwd()}/input/{base_filename[:-5]}_Test.json\"\n",
    "\n",
    "with open(train_file, \"w\") as file:\n",
    "    json.dump(train_json, file)\n",
    "    print(f\"Final training set file saved as: {train_file}\")\n",
    "\n",
    "with open(valid_file, \"w\") as file:\n",
    "    json.dump(valid_json, file)\n",
    "    print(f\"Final valid set file saved as: {valid_file}\")\n",
    "\n",
    "with open(test_file, \"w\") as file:\n",
    "    json.dump(test_json, file)\n",
    "    print(f\"Final test set file saved as: {test_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7TF5g6O0HCWh"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "path = os.getcwd()\n",
    "path_images = os.getcwd() + '/images'\n",
    "\n",
    "register_coco_instances(\"escooter_train\", {}, train_file, '')\n",
    "register_coco_instances(\"escooter_valid\", {}, valid_file, '')\n",
    "register_coco_instances(\"escooter_test\", {}, test_file, '')\n",
    "\n",
    "existing_files = []\n",
    "for img in os.listdir(path_images):\n",
    "  fileName = path_images + '/' + img\n",
    "  existing_files.append(fileName)\n",
    "\n",
    "dataset_dicts = DatasetCatalog.get(\"escooter_train\")\n",
    "\n",
    "# List of labelled_images for visualization purposes\n",
    "out_files = []\n",
    "for d in dataset_dicts:\n",
    "    # Adjusting for difference in frame\n",
    "    file_name_from_dict = d[\"file_name\"].split('.')[0]\n",
    "    file_number = int(file_name_from_dict[-6:])\n",
    "    \n",
    "    # 1 is the offset number for the frame difference between the annotations \n",
    "    # from CVAT and frames extracted from the FFMPEG Script\n",
    "    file_number += 1\n",
    "    \n",
    "    # Adding the write number of 0's and taking care of proper filename\n",
    "    if int(file_number / 10) == 0:\n",
    "      new_file_name = file_name_from_dict[:-6] + '00000' + str(file_number) + '.png'\n",
    "    elif int(file_number / 100) == 0:\n",
    "      new_file_name = file_name_from_dict[:-6] + '0000' + str(file_number) + '.png'\n",
    "    elif int(file_number / 1000) == 0:\n",
    "      new_file_name = file_name_from_dict[:-6] + '000' + str(file_number) + '.png'\n",
    "    elif int(file_number / 10000) == 0:\n",
    "      new_file_name = file_name_from_dict[:-6] + '00' + str(file_number) + '.png'\n",
    "    \n",
    "  \n",
    "    \n",
    "    if new_file_name in existing_files:   \n",
    "      print(new_file_name)  \n",
    "      file_name = new_file_name\n",
    "      img = cv2.imread(file_name)\n",
    "  \n",
    "      visualizer = Visualizer(img[:, :, ::-1], scale=1)\n",
    "      out = visualizer.draw_dataset_dict(d)\n",
    "      \n",
    "      #cv2_imshow(out.get_image()[:, :, ::-1])\n",
    "\n",
    "      out_filename = file_name[:-4] + '_labelled.png'\n",
    "      out_filename = '/content/images/labels/' + file_name[:-4].split('/')[-1] + '.png'\n",
    "      cv2.imwrite(out_filename, out.get_image()[:, :, ::-1])\n",
    "      out_files.append(out_filename)\n",
    "\n",
    "\n",
    "for images in out_files:\n",
    "  display(Image(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y4lz0o5-chBi"
   },
   "source": [
    "# Training the model\n",
    "\n",
    "We are using transfer learning here to use an already COCO-pretrained R50-FPN Mask R-CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eR2KTj5JcfGS"
   },
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"escooter_train\",)\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 300    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n",
    "cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 256   # faster, and good enough for this toy dataset (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
    "# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1yDEcrn3rXki"
   },
   "outputs": [],
   "source": [
    "# Look at training curves in tensorboard:\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir output"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Escooter Tracking.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
